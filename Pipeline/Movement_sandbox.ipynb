{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f439fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "import ruptures as rpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f36f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDF(path): \n",
    "    '''converting a dataframe to a new datafrom with float, 5 decimal places and '''\n",
    "\n",
    "    # reading in file, and skipping top row\n",
    "    df = pd.read_csv(path, skiprows=1)\n",
    "\n",
    "    print(df)\n",
    "\n",
    "    # defining the titles of the rows\n",
    "    body_loc = df.columns.tolist()\n",
    "\n",
    "    # creating new empty dataframe\n",
    "    df_new = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for part in body_loc:\n",
    "        if part == 'bodyparts' in part:\n",
    "            continue\n",
    "        else:\n",
    "            df_new[part] = pd.to_numeric(df[part].iloc[1:], errors='coerce').dropna().round(5).astype(float)\n",
    "\n",
    "\n",
    "    # Copy your DataFrame\n",
    "    cleaned_df = df_new.copy()\n",
    "\n",
    "    # Get base marker names by stripping '.1' and '.2'\n",
    "    marker_names = {'PalmBase', 'MCP1', 'MCP2', 'MCP3', 'MCP4', 'MCP5', 'fTip1', 'fTip2', 'fTip3', 'fTip4', 'fTip5', 'MidForeArm', 'Elbow', 'MidUpperArm'}\n",
    "\n",
    "    print(marker_names)\n",
    "\n",
    "    for marker in marker_names:\n",
    "        x_col = marker\n",
    "        y_col = marker + '.1'\n",
    "        l_col = marker + '.2'\n",
    "\n",
    "        # Phase 1: Find first row where likelihood >= 0.8\n",
    "        # Boolean mask for where likelihood >= 0.95\n",
    "        high_likelihood = cleaned_df[l_col] >= 0.95\n",
    "\n",
    "        # Find where two consecutive values are both True\n",
    "        consecutive_valid = high_likelihood & high_likelihood.shift(-1, fill_value=False)\n",
    "\n",
    "        # Get the index of the first such occurrence\n",
    "        first_valid_idx = consecutive_valid[consecutive_valid].index.min()\n",
    "\n",
    "        # Remove all rows before first high-confidence point\n",
    "        cleaned_df.loc[:first_valid_idx - 1, [l_col]] = np.nan\n",
    "\n",
    "        # Phase 2: Set x/y to NaN where likelihood < 0.95\n",
    "        low_conf_mask = cleaned_df[l_col] < 0.95\n",
    "        cleaned_df.loc[low_conf_mask, [x_col, y_col]] = np.nan\n",
    "\n",
    "        # Interpolate x and y\n",
    "        cleaned_df[[x_col, y_col]] = cleaned_df[[x_col, y_col]].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # Phase 3: Set x and y to 0 where likelihood is NaN\n",
    "        nan_likelihood_mask = cleaned_df[l_col].isna()\n",
    "        cleaned_df.loc[nan_likelihood_mask, [x_col, y_col]] = 0\n",
    "\n",
    "\n",
    "    # (Optional) Reset index or drop NaNs if needed\n",
    "    # cleaned_df = cleaned_df.dropna(subset=marker_names)  # if you want to drop completely bad rows\n",
    "\n",
    "    # cleaned_df now has cleaned x/y data based on per-marker likelihoods\n",
    "\n",
    "    cleaned_df\n",
    "\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390efe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining my path to pt one\n",
    "IO_03_09_2023_RSTN = Path(r'X:\\RadcliffeE\\for_MorganHampton_BoettcherScholar\\Subject Case Data\\IO_03_09_2023_RSTN\\Processed DLC\\csv folder')\n",
    "\n",
    "# list of all the videos for this specific patient (c1s is missing for this patient)\n",
    "dbs_loc = ['b1f', 'b1s', 'b2f', 'b2s', 'b3f', 'b3s', 'c1f', 'c1s', 'c2s', 'c3f', 'c3s', 't1f', 't1s', 't2f', 't2s', 't3f', 't3s']\n",
    "\n",
    "# place to store all the df\n",
    "dataframes = {}\n",
    "\n",
    "files = list(IO_03_09_2023_RSTN.iterdir())\n",
    "\n",
    "# iterating over each file for pt 1 and converting the df to floats and cleaning up the data\n",
    "for file, label in zip(IO_03_09_2023_RSTN.iterdir(), dbs_loc):\n",
    "    dataframes[label] = convertDF(file)\n",
    "    print(f\"{label} loaded from {file.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize an empty dictionary to hold results by base label\n",
    "results_dict = {}\n",
    "\n",
    "for df_name, data in dataframes.items():\n",
    "    # Extract base label (e.g. 'b1' from 'b1f' or 'b1s')\n",
    "    base_label = df_name[:-1]  # remove last character\n",
    "    view = 'front' if df_name.endswith('f') else 'side'\n",
    "\n",
    "    points = data['MCP1.1']\n",
    "    points_np = points.to_numpy()\n",
    "\n",
    "    algo = rpt.Pelt(model='l2').fit(points_np)\n",
    "    change_points = algo.predict(pen=1e6)\n",
    "\n",
    "    # Initialize dict entry if not exists\n",
    "    if base_label not in results_dict:\n",
    "        results_dict[base_label] = {'front': None, 'side': None}\n",
    "\n",
    "    # Save change points in proper column\n",
    "    results_dict[base_label][view] = change_points\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df_indices = pd.DataFrame.from_dict(results_dict, orient='index').reset_index()\n",
    "df_indices.rename(columns={'index': 'dataset'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_list = []\n",
    "\n",
    "for _, row in df_indices.iterrows():\n",
    "    # Check if number of change points in 'front' view is 4 or 5\n",
    "    num_cp = len(row['front']) if isinstance(row['front'], list) else 0\n",
    "\n",
    "    if num_cp in [4, 5]:\n",
    "        success_list.append(f\"{row['dataset']}f\")\n",
    "    else:\n",
    "        success_list.append(f\"{row['dataset']}s\")\n",
    "\n",
    "print(success_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ruptures-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
